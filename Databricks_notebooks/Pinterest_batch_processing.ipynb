{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98c71fd3-83b7-4d63-8c45-d93993e9c884",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b88888fc-07ff-4620-a51d-ade734611666",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "903056ff-203a-459d-85b2-93cbb056811c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data cleaning\n",
    "A function was created to read data from S3 bucket into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "191aa480-640f-4944-b4d3-a8eda32d36c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_s3_data(mount_name):\n",
    "    \"\"\"\n",
    "    Reads JSON data from an S3 mount point into a Spark DataFrame.\n",
    "\n",
    "    Args:\n",
    "        mount_name (str): The name of the S3 mount point.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A Spark DataFrame containing the read JSON data.\n",
    "    \"\"\"\n",
    "\n",
    "    file_location = f\"/mnt/{mount_name}/*.json\"\n",
    "    file_type = \"json\"\n",
    "    infer_schema = \"true\"\n",
    "    df = spark.read.format(file_type) \\\n",
    "    .option(\"inferSchema\", infer_schema) \\\n",
    "    .load(file_location)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee8ff92-e984-42dc-aa7a-139d22d1fafc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Reading the pin data and cleaning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "069351ad-57ee-4b8e-abda-916a93554322",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reading the data\n",
    "df_pin = read_s3_data()\n",
    "\n",
    "# replacing invalid entries with `None`\n",
    "columns_to_clean = ['category', 'description', 'follower_count', 'poster_name', 'tag_list', 'is_image_or_video', 'image_src', 'save_location', 'unique_id', 'title']\n",
    "\n",
    "for column in columns_to_clean:\n",
    "    df_pin = df_pin.replace({\"\": None}, subset=[column])\n",
    "# replacing k and M with 000 and 000000 respectivly.\n",
    "df_pin = (df_pin\n",
    "    .withColumn('follower_count', \n",
    "        when(df_pin.follower_count.endswith('k'), regexp_replace(df_pin.follower_count, 'k', '000'))\n",
    "        .when(df_pin.follower_count.endswith('M'), regexp_replace(df_pin.follower_count, 'M', '000000'))\n",
    "        .otherwise(df_pin.follower_count))\n",
    ")\n",
    "# casting follower count to integers\n",
    "df_pin = df_pin.withColumn('follower_count', df_pin.follower_count.cast('int'))\n",
    "\n",
    "# renaming index to ind.\n",
    "df_pin = df_pin.withColumnRenamed('index', 'ind')\n",
    "\n",
    "# adjusting the 'save_location' column to display the path\n",
    "df_pin = df_pin.withColumn('save_location', regexp_replace( 'save_location', 'Local save in ', ''))\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "column_order = ['ind', 'unique_id', 'title', 'description', 'follower_count', \n",
    "                'poster_name', 'tag_list', 'is_image_or_video', 'image_src', \n",
    "                'save_location', 'category']\n",
    "df_pin = df_pin.select(column_order)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6d419c9-cfbf-4fba-afbd-7a90b30fa57c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reorder the DataFrame columns\n",
    "column_order = ['ind', 'unique_id', 'title', 'description', 'follower_count', \n",
    "                'poster_name', 'tag_list', 'is_image_or_video', 'image_src', \n",
    "                'save_location', 'category']\n",
    "df_pin = df_pin.select(column_order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "874030ac-32be-497c-8436-a27ed927a238",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Reading the geo data and cleaning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca510be9-688e-4679-b104-fedb91e5cad7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reading the data\n",
    "df_geo = read_s3_data()\n",
    "\n",
    "# Create a new column 'coordinates' containing an array based on 'latitude' and 'longitude' columns\n",
    "df_geo = df_geo.withColumn('coordinates', array(df_geo.latitude, df_geo.longitude))\n",
    "\n",
    "# Drop the 'latitude' and 'longitude' columns from the DataFrame\n",
    "df_geo = df_geo.drop('latitude', 'longitude')\n",
    "\n",
    "# converting 'timestamp' to a timestamp data type, and formatting it.\n",
    "df_geo = df_geo.withColumn('timestamp', to_timestamp(df_geo.timestamp))\n",
    "df_geo = df_geo.withColumn('timestamp', date_format('timestamp', 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "# reordering the dataframe columns\n",
    "df_geo = df_geo.select('ind','country','coordinates','timestamp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fafbf591-4b7f-4773-976e-3fb08c387587",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Reading the user data and cleaning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98697695-e288-4df6-b5a7-95c873215df8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reading the data\n",
    "df_user = read_s3_data()\n",
    "\n",
    "# Create a new column 'user_name' by concatenating 'first_name' and 'last_name' columns\n",
    "df_user = df_user.withColumn('user_name', concat_ws('', col('first_name'), col('last_name')))\n",
    "\n",
    "# Drop the 'first_name' and 'last_name' columns from the DataFrame\n",
    "df_user = df_user.drop(\"first_name\", \"last_name\")\n",
    "\n",
    "# converting 'date_joined' to a timestamp data type, and formatting it.\n",
    "df_user = df_user.withColumn('date_joined', to_timestamp(df_user.date_joined))\n",
    "df_user = df_user.withColumn('date_joined', date_format('date_joined', 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "# reordering columns\n",
    "df_user = df_user.select('ind', 'user_name', 'age', 'date_joined')\n",
    "\n",
    "# Ensure 'ind' and 'age' columns are casted to the appropriate data types\n",
    "df_user = df_user.withColumn(\"ind\", df_user[\"ind\"].cast(\"int\"))\n",
    "df_user = df_user.withColumn(\"age\", df_user[\"age\"].cast(\"int\"))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ac1da78-c0df-43b8-8957-32c89f85fbc2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Querying the data\n",
    "Find the most popular Pinterest category people post to based on their country.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f589f97-0533-4c4e-94db-c50b3fe9433f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join df_pin with df_geo based on unique_id to get the country information\n",
    "joined_df = df_pin.join(df_geo.select(\"ind\", \"country\"), on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Group the data by country and category, and count the occurrences of each category within each country\n",
    "category_count_df = joined_df.groupby(\"country\", \"category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "\n",
    "# Rank the categories within each country based on the category count\n",
    "windowSpec = Window.partitionBy(\"country\").orderBy(col(\"category_count\").desc())\n",
    "ranked_category_count_df = category_count_df.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to keep only the top-ranked category for each country\n",
    "most_popular_category_df = ranked_category_count_df.filter(col(\"rank\") == 1).drop(\"rank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3bed8cd-0894-48b2-b27c-892c546ecc8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Find how many posts each category had between 2018 and 2022.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "280084d0-bd93-4628-aa3f-f93a7358cac0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# creating temporary dataframes\n",
    "df_pin.createOrReplaceTempView('df_temp_pin')\n",
    "df_geo.createOrReplaceTempView('df_temp_geo')\n",
    "\n",
    "# the SQL query\n",
    "\n",
    "#creating a CTE\n",
    "cte_query = \"\"\"\n",
    "       WITH ranking_table AS (\n",
    "              SELECT year(df_temp_geo.timestamp) AS post_year,\n",
    "                     df_temp_pin.category AS category,\n",
    "                     COUNT(df_temp_pin.category) AS category_count,\n",
    "                     RANK() OVER (PARTITION BY year(df_temp_geo.timestamp) ORDER BY COUNT(df_temp_pin.category) DESC) AS rank\n",
    "              FROM df_temp_geo\n",
    "              JOIN df_temp_pin ON df_temp_geo.ind = df_temp_pin.ind  \n",
    "              WHERE 2018 <= year(df_temp_geo.timestamp) AND year(df_temp_geo.timestamp) <= 2022\n",
    "              GROUP BY year(df_temp_geo.timestamp), df_temp_pin.category     \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(cte_query + \"\"\"\n",
    "                     SELECT post_year,\n",
    "                           category,\n",
    "                           category_count\n",
    "                     FROM ranking_table\n",
    "                     WHERE rank == 1\n",
    "                      \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "584bb765-fe2b-4a28-b24d-715a17fcf155",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Find the user with most followers with their corresponding country\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06fc9e53-d6c3-4a72-8308-1c2e3395b9ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# creating temporary dataframes\n",
    "df_pin.createOrReplaceTempView('df_temp_pin')\n",
    "df_geo.createOrReplaceTempView('df_temp_geo')\n",
    "\n",
    "# SQL query \n",
    "cte_query = \"\"\"\n",
    "       WITH ranking_table AS (\n",
    "              SELECT df_temp_geo.country AS country,\n",
    "                     df_temp_pin.poster_name AS poster_name,\n",
    "                     df_temp_pin.follower_count AS follower_count,\n",
    "                     RANK() OVER(PARTITION BY df_temp_geo.country ORDER BY df_temp_pin.follower_count DESC) AS rank\n",
    "              FROM df_temp_pin\n",
    "              JOIN df_temp_geo ON df_temp_geo.ind = df_temp_pin.ind\n",
    "       )\n",
    "\"\"\"\n",
    "result_2 = spark.sql(cte_query + \"\"\"\n",
    "                    SELECT country,\n",
    "                           poster_name,\n",
    "                           follower_count\n",
    "                    FROM ranking_table\n",
    "                    WHERE rank == 1\n",
    "                    ORDER BY follower_count DESC\n",
    "                      \"\"\")\n",
    "                  \n",
    "result_2 = spark.createDataFrame([result_2.head(1)[0]])\n",
    "result_2 = result_2.drop('poster_name')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a0f1c5c-308f-44ab-8bd7-dc831c9a5c99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "What is the most popular category people post to based on age groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f62dd56f-f649-4452-8632-7f4873762b02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  # Join df_pin with df_user based on the common column 'ind' to get the age information\n",
    "  joined_df = df_pin.join(df_user.select(\"ind\", \"age\"), on=\"ind\", how=\"inner\")\n",
    "\n",
    "  # Categorize the age groups based on the original age column\n",
    "  df_pin_age_group = joined_df.withColumn(\"age_group\",\n",
    "      when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "      .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "      .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "      .otherwise(\"+50\")\n",
    "  )\n",
    "\n",
    "  # Group the data by age group and category, and count the occurrences of each category within each age group\n",
    "  category_count_df = df_pin_age_group.groupBy(\"age_group\", \"category\").agg(count(\"*\").alias(\"category_count\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73d41f2b-77b8-41d9-ab8d-18a4358cddf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " What is the median follower count for users in different age groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e27deda5-1644-4c9f-837c-84585892a5c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Join df_user_cleaned with df_pin based on the common column 'poster_name' to get the age and follower count information\n",
    "joined_df = df_user.join(df_pin.select(\"ind\", \"follower_count\"), on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Categorize the age groups based on the original age column\n",
    "df_age_group = joined_df.withColumn(\"age_group\",\n",
    "    when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "    .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "    .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "    .otherwise(\"+50\")\n",
    ")\n",
    "\n",
    "# Calculate the median follower count for each age group\n",
    "median_follower_count_df = df_age_group.groupBy(\"age_group\").agg(\n",
    "    percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "794448a5-802a-41ec-b48a-9a544417590c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Find how many users have joined between 2015 and 2020.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49e1f747-61c1-4d43-8ff7-b9d48486f6f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Join df_user with df_geo based on a common key to get the date_joined information\n",
    "joined_df = df_user.join(df_geo.select(\"ind\", \"timestamp\"), on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Extract the year from the timestamp column\n",
    "joined_df = joined_df.withColumn(\"join_year\", year(\"timestamp\"))\n",
    "\n",
    "# Filter the DataFrame to select users who joined between 2015 and 2020\n",
    "filtered_df = joined_df.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Group the data by join year and count the number of users who joined each year\n",
    "number_users_joined_df = filtered_df.groupBy(\"join_year\").agg(count(\"*\").alias(\"number_users_joined\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a435a62-4dc7-4161-a2c5-0e351659e354",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Find the median follower count of users have joined between 2015 and 2020.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "611a0db7-1a75-4d54-bfc1-194b8963314a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3aaf1a51-2a21-4a50-b48c-47c7d458d202",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Join df_user_cleaned with df_pin based on the common column 'poster_name' to get the follower count information\n",
    "joined_df = df_user.join(df_pin.select(\"ind\", \"follower_count\"), on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "joined_df = joined_df.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the DataFrame to select users who joined between 2015 and 2020\n",
    "filtered_df = joined_df.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Calculate the median follower count for the selected users\n",
    "median_follower_count_df = filtered_df.groupBy(\"join_year\").agg(\n",
    "    percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec31239b-ecda-4e1c-ac62-3fee933bc4b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Find the median follower count of users that have joined between 2015 and 2020, based on  age group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fda50ee2-1275-4490-9564-c4d7ce7d3e90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join df_user_cleaned with df_pin_cleaned based on the common column 'poster_name' to get the follower count information\n",
    "joined_df = df_user_cleaned.join(df_pin_cleaned.select(\"ind\", \"follower_count\"), on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "joined_df = joined_df.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the DataFrame to select users who joined between 2015 and 2020\n",
    "filtered_df = joined_df.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Categorize the age groups based on the original age column\n",
    "filtered_df = filtered_df.withColumn(\"age_group\",\n",
    "    when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "    .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "    .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "    .otherwise(\"+50\")\n",
    ")\n",
    "\n",
    "# Calculate the median follower count for each age group\n",
    "median_follower_count_df = filtered_df.groupBy(\"age_group\", \"join_year\").agg(\n",
    "    percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2297951191714135,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Pinterest_batch_processing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
